{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{277:function(t,s,a){\"use strict\";a.r(s);var n=a(39),r=Object(n.a)({},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[a(\"h1\",{attrs:{id:\"前言\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#前言\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 前言\")]),t._v(\" \"),a(\"p\",[t._v(\"笔者花了一个月的时间学习了线段树，但是那玩意儿\"),a(\"s\",[t._v(\"又臭又长\")]),t._v(\"常数又大，就打算探究一种新的算法。于是我就学习了树状数组。\")]),t._v(\" \"),a(\"h1\",{attrs:{id:\"引入概念\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#引入概念\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 引入概念\")]),t._v(\" \"),a(\"p\",[t._v(\"树状数组和线段树类似，都是处理区间上问题的，但又略有不同。树状数组的性质：\")]),t._v(\" \"),a(\"ol\",[a(\"li\",[t._v(\"一个节点，编号是$x$，则它的父亲节点编号是$x+lowbit(x)$，且最顶层节点的编号就是数组的长度;\")]),t._v(\" \"),a(\"li\",[t._v(\"一个节点，编号是$x$，则它的管辖范围是$\\\\left( x-lowbit(x),x \\\\right]$。\")])]),t._v(\" \"),a(\"h2\",{attrs:{id:\"lowbit-函数\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#lowbit-函数\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" $lowbit$函数\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"概念\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#概念\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 概念\")]),t._v(\" \"),a(\"p\",[t._v(\"$lowbit(x)$表示x二进制下最低位的$1$的数码。比如:\")]),t._v(\" \"),a(\"p\",[t._v(\"$$lowbit(5)=lowbit((0101)_2)=(1)_2=1$$\")]),t._v(\" \"),a(\"p\",[t._v(\"$$lowbit(24)=lowbit((00011000)_2)=(1000)_2=8$$\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"实现\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#实现\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 实现\")]),t._v(\" \"),a(\"p\",[t._v(\"知道了$lowbit$的概念，我们该怎么去求呢？\")]),t._v(\" \"),a(\"p\",[t._v(\"假设要求的数是$24$，我们先把它转换成二进制数$00011000$，然后对这个二进制数\"),a(\"strong\",[t._v(\"取补码\")]),t._v(\"，结果是二进制数$11101110$，然后\"),a(\"strong\",[t._v(\"与\")]),t._v(\"一下可得到二进制数$1000$，也就是最后结果。为什么呢？\")]),t._v(\" \"),a(\"p\",[t._v(\"我们可以把取补码的步骤拆开来。先取反码，得到$11100111$，然后加$1$，得到$11101110$，发现刚好把最低位的$0$右边的所有$1$向左移了一位，覆盖掉了这个$0$，而这个$0$的位置在原码上是$1$，与一下自然就是$1$，最后结果自然就是$lowbit$了。\")]),t._v(\" \"),a(\"p\",[t._v(\"由于取补码相当于取负，那么$lowbit(x)$就等于$x&(-x)$，代码显而易见：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"h1\",{attrs:{id:\"树状数组实现\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#树状数组实现\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 树状数组实现\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"单点加减-区间求和\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#单点加减-区间求和\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 单点加减+区间求和\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"建树\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#建树\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 建树\")]),t._v(\" \"),a(\"p\",[t._v(\"树状数组不用建树，只要把需要加入树状数组的数依次加进去就好了。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"单点加减-修改第-x-个元素\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#单点加减-修改第-x-个元素\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 单点加减-修改第$x$个元素\")]),t._v(\" \"),a(\"p\",[t._v(\"其实单点修改很简单，只要将树状数组中的第$x$个元素修改，再向上维护即可。\")]),t._v(\" \"),a(\"p\",[t._v(\"代码：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//tot表示总共有tot个元素。\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//维护树状数组\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"h3\",{attrs:{id:\"区间求和-查询-left-l-r-right-区间内所有数的和\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#区间求和-查询-left-l-r-right-区间内所有数的和\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 区间求和-查询$\\\\left[ l,r \\\\right]$区间内所有数的和\")]),t._v(\" \"),a(\"p\",[t._v(\"我们设定一个查询函数，每次调用查询函数传入一个$x$，查询$1$~$x$区间内所有数的和。这个函数代码如下：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" ans\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"p\",[t._v(\"$query(r)-query(l-1)$就是最终结果。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"推荐题目\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#推荐题目\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 推荐题目\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"https://www.luogu.org/problemnew/show/P3374\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"洛谷P3374\"),a(\"OutboundLink\")],1),t._v(\"\\n该题代码如下：\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token macro property\"}},[t._v(\"#\"),a(\"span\",{pre:!0,attrs:{class:\"token directive keyword\"}},[t._v(\"include\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"<cstdio>\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"using\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"namespace\")]),t._v(\" std\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"20000001\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//单点修改\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//区间查询\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" ans\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"main\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//初始化\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d%d%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d\\\\n\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"hr\"),t._v(\" \"),a(\"center\",[t._v(\"Updated on Jun. 9th, 2019\")]),t._v(\" \"),a(\"h2\",{attrs:{id:\"区间加减-单点查询\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#区间加减-单点查询\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 区间加减+单点查询\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"差分\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#差分\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 差分\")]),t._v(\" \"),a(\"p\",[t._v(\"在这个问题里，我们不再记录每个数具体的值，而是记录这个数与它前一个数的差。这会非常有效地解决区间加减的问题。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"建树-2\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#建树-2\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 建树\")]),t._v(\" \"),a(\"p\",[t._v(\"照样不需要建树。但是，这与前面的初始化方法又略有不同：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" pre\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//初始化\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"pre\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    pre\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//记录前一个数\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"h3\",{attrs:{id:\"区间加-将-left-l-r-right-区间内所有数加上-n\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#区间加-将-left-l-r-right-区间内所有数加上-n\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 区间加-将$\\\\left[ l,r \\\\right]$区间内所有数加上$n$\")]),t._v(\" \"),a(\"p\",[t._v(\"我们只要把差分数组中第$l$个元素加上$n$，再将第$r+1$个元素减去$n$即可。\")]),t._v(\" \"),a(\"p\",[t._v(\"代码：\")]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"modifyAdd\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" l\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" r\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"l\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"r\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//一个数减去另一个数等于加上那个数的相反数\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])]),a(\"h3\",{attrs:{id:\"单点查询-查询第-x-个元素的值\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#单点查询-查询第-x-个元素的值\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 单点查询-查询第$x$个元素的值\")]),t._v(\" \"),a(\"p\",[t._v(\"我们如何从差分数组中还原第$x$数呢？其实很简单，只要将差分数组中前$x$个数加起来就行了。代码和上面的$query$函数一样。\")]),t._v(\" \"),a(\"h3\",{attrs:{id:\"推荐题目-2\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#推荐题目-2\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" 推荐题目\")]),t._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"https://www.luogu.org/problemnew/show/P3368\",target:\"_blank\",rel:\"noopener noreferrer\"}},[t._v(\"洛谷P3368\"),a(\"OutboundLink\")],1),t._v(\"\\n该题代码如下：\")])]),t._v(\" \"),a(\"div\",{staticClass:\"language-cpp extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-cpp\"}},[a(\"code\",[a(\"span\",{pre:!0,attrs:{class:\"token macro property\"}},[t._v(\"#\"),a(\"span\",{pre:!0,attrs:{class:\"token directive keyword\"}},[t._v(\"include\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v(\"<iostream>\")])]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"using\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"namespace\")]),t._v(\" std\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1000001\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"modifyAdd\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" l\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" r\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//区间加\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"l\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"r\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"tot\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"index\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        ans\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\"tree\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-=\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"lowbit\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" ans\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"main\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"pre\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<=\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//初始化\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\t\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"-\")]),t._v(\"pre\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        pre\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"while\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"--\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"z\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\t\\t\"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"if\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"m\"),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"==\")]),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"scanf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d%d\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"&\")]),t._v(\"z\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"modifyAdd\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"y\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"z\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\"n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"else\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printf\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"%d\\\\n\"')]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),a(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"query\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),a(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"return\")]),t._v(\" \"),a(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])])],1)},[],!1,null,null,null);s.default=r.exports}}]);","extractedComments":[]}